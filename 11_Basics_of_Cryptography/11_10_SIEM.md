| **Inicio**         | **atr√°s 9**            | **Siguiente 11**      |
| ------------------ | ---------------------- | --------------------- |
| [üè†](../README.md) | [‚è™](./11_9_ATT&CK.md) | [‚è©](./11_11_SOAR.md) |

---

## **√çndice**

| Temario                                                                                                      |
| ------------------------------------------------------------------------------------------------------------ |
| [351. Seguridad 101: ¬øQu√© es un SIEM? - Microsoft](#351-seguridad-101-qu√©-es-un-siem---microsoft)            |
| [352. Explicaci√≥n del SIEM](#352-explicaci√≥n-del-siem)                                                       |
| [353. Wazuh SIEM de c√≥digo abierto](#353-wazuh-siem-de-c√≥digo-abierto)                                       |
| [354. Splunk El tutorial completo para principiantes](#354-splunk-el-tutorial-completo-para-principiantes)   |
| [355. Elastic Security Cree un SIEM dom√©stico potente](#355-elastic-security-cree-un-siem-dom√©stico-potente) |
|                                                                                                              |

# **SIEM**

## **351. Seguridad 101: ¬øQu√© es un SIEM? - Microsoft**

![SIEM](/img/11_Basics_of_Cryptography/SIEM.jpeg "SIEM")

### 1) Introducci√≥n a SIEM

**SIEM (Security Information and Event Management)** es una plataforma que **centraliza, correlaciona y analiza registros (logs) de seguridad** provenientes de diferentes sistemas y dispositivos en una red.
Su objetivo es **detectar incidentes, responder r√°pidamente y ayudar en el cumplimiento normativo**.

üëâ Ejemplo cotidiano:

Un **SIEM** recibe logs de un firewall, un servidor Windows y un antivirus. Si ve que:

- Hubo un inicio de sesi√≥n fallido 50 veces,
- Luego una conexi√≥n sospechosa a un pa√≠s extra√±o,
- Y el antivirus detect√≥ un malware,
  El SIEM puede correlacionar todo y generar una **alerta prioritaria para el SOC**.

### 2) Historia y evoluci√≥n de SIEM

- **A√±os 90 ‚Äì SIM (Security Information Management):** enfoque en almacenamiento de logs para auditor√≠a y cumplimiento.
- **A√±os 2000 ‚Äì SEM (Security Event Management):** enfoque en la correlaci√≥n y alertas en tiempo real.
- **Actualidad ‚Äì SIEM:** fusi√≥n de SIM + SEM ‚Üí an√°lisis hist√≥rico + monitoreo en tiempo real, con capas de inteligencia artificial, machine learning y automatizaci√≥n.

üëâ Evoluci√≥n moderna: muchos SIEM ahora integran **SOAR** (Security Orchestration, Automation and Response) para automatizar respuestas.

### 3) Componentes clave de SIEM

Un SIEM t√≠pico incluye:

1. **Recolecci√≥n de logs**: captura datos desde firewalls, IDS/IPS, servidores, endpoints, aplicaciones, cloud, etc.
2. **Normalizaci√≥n**: convierte formatos distintos en un modelo com√∫n.
3. **Almacenamiento seguro**: base de datos centralizada para b√∫squeda e investigaci√≥n.
4. **Correlaci√≥n**: combina eventos aparentemente aislados en incidentes significativos.
5. **Alertas y reportes**: notifica al SOC con priorizaci√≥n (seg√∫n riesgo, gravedad, contexto).
6. **Dashboards**: panel visual para monitoreo en tiempo real.
7. **An√°lisis forense**: b√∫squeda avanzada y reconstrucci√≥n de incidentes pasados.
8. **Integraci√≥n con CTI (Cyber Threat Intelligence)**: para detectar IOCs conocidos.

### 4) C√≥mo funciona SIEM

1. **Ingesta**: logs entran desde m√∫ltiples fuentes (firewalls, AD, proxies, servidores).
2. **Parseo y normalizaci√≥n**: convierten datos brutos en eventos legibles.
3. **Correlaci√≥n**: el SIEM aplica reglas (ej. ‚Äúsi 10 fallos de login en 5 minutos desde la misma IP ‚Üí alerta brute force‚Äù).
4. **Alerta**: se genera incidente y se prioriza seg√∫n criticidad.
5. **An√°lisis e investigaci√≥n**: analistas SOC revisan, buscan evidencias, responden.
6. **Respuesta (manual o autom√°tica)**: bloquear IP, aislar endpoint, enviar notificaci√≥n.

üëâ Ejemplo:

- Usuario intenta 20 logins fallidos en un servidor.
- Inmediatamente accede con √©xito desde una IP extranjera.
- Empieza a descargar muchos datos.

  El **SIEM** correlaciona esto ‚Üí alerta de **posible compromiso de cuenta + exfiltraci√≥n de datos**.

### 5) Ventajas de SIEM

‚úÖ **Visibilidad centralizada** de toda la red.

‚úÖ **Detecci√≥n de amenazas avanzadas** mediante correlaci√≥n.

‚úÖ **Respuesta m√°s r√°pida** a incidentes.

‚úÖ **Cumplimiento normativo** (ISO 27001, PCI-DSS, HIPAA, GDPR).

‚úÖ **Soporte a forense digital** (hist√≥rico de logs).

‚úÖ **Integraci√≥n con Threat Intel y SOAR** para enriquecer y automatizar.

### 6) Claves para una implementaci√≥n exitosa de SIEM

- **Definir objetivos claros** (detecci√≥n, cumplimiento, respuesta).
- **Ingestar las fuentes correctas** (no todos los logs, sino los relevantes: AD, endpoints cr√≠ticos, firewalls).
- **Optimizar reglas de correlaci√≥n** (evitar falsos positivos).
- **Capacitar al SOC** en uso de SIEM.
- **Escalabilidad**: almacenamiento y procesamiento deben crecer con la organizaci√≥n.
- **Integraci√≥n** con EDR, NDR, SOAR, CTI.
- **Mantenimiento continuo**: ajuste de reglas, actualizaci√≥n de IOCs, revisi√≥n de dashboards.

### 7) Casos de uso de SIEM

- **Detecci√≥n de brute force** en Active Directory.
- **Exfiltraci√≥n de datos** (descargas masivas desde servidor sensible).
- **Malware detectado** en m√∫ltiples endpoints ‚Üí correlaci√≥n con IOC global.
- **Cumplimiento** ‚Üí auditor√≠a de accesos a sistemas financieros.
- **Threat hunting** ‚Üí buscar TTPs del marco MITRE ATT\&CK en los logs hist√≥ricos.
- **Insider threats** ‚Üí empleado accede a informaci√≥n fuera de su rol normal.

### 8) Tendencias emergentes en SIEM

üöÄ **SIEM en la nube**: Splunk Cloud, Azure Sentinel, QRadar on Cloud.

ü§ñ **IA y Machine Learning**: detecci√≥n de anomal√≠as m√°s all√° de reglas est√°ticas.

üîó **Integraci√≥n con XDR**: unir SIEM + EDR + NDR en un solo ecosistema.

‚ö° **Automatizaci√≥n (SOAR)**: respuesta autom√°tica ante incidentes.

üîê **Zero Trust**: correlaci√≥n de identidades, accesos y microsegmentaci√≥n.

üß© **MITRE ATT\&CK mapping**: reglas y dashboards alineados con t√°cticas y t√©cnicas adversarias.

### 9) Soluciones SIEM

Algunas de las plataformas SIEM m√°s usadas:

- **Splunk** (muy potente, flexible, pero costosa).
- **IBM QRadar** (robusta en correlaci√≥n, usada en grandes empresas).
- **Microsoft Sentinel** (nativa en la nube, integraci√≥n con Azure).
- **ArcSight (Micro Focus)** (hist√≥ricamente fuerte, a√∫n usada).
- **LogRhythm** (buena relaci√≥n costo-beneficio).
- **Elastic SIEM (Elastic Stack)** (open source, muy adoptada en startups y SOCs modernos).
- **Graylog** (open source, ligera, popular en PyMEs).

‚úÖ **En resumen**:

El **SIEM** es el ‚Äúcerebro‚Äù de la seguridad de una organizaci√≥n, ya que permite **unificar, correlacionar y analizar eventos de seguridad en tiempo real**. Evolucion√≥ de simples recolectores de logs a plataformas inteligentes con IA y automatizaci√≥n.

---

[üîº](#√≠ndice)

---

## **352. Explicaci√≥n del SIEM**

### ¬øQu√© es un SIEM (en una frase)?

Un **SIEM (Security Information and Event Management)** es una plataforma que **centraliza, normaliza, correlaciona y analiza** logs y eventos de seguridad de m√∫ltiples fuentes para detectar amenazas, soportar la investigaci√≥n forense y automatizar respuestas.

### Arquitectura y flujo b√°sico (visi√≥n pr√°ctica)

ASCII r√°pido de la arquitectura:

```
[Endpoints EDR]  [Firewalls]  [Proxy/Web]  [DNS]  [AD/Auth]  [Cloud]
      \            |           |          |       |         /
       \_________ Ingest / Forwarders___________/
                        |
                [Log Collector / Broker]
                        |
               [Parsing / Normalization]
                        |
                 [Enrichment (CTI, GeoIP, AssetDB)]
                        |
                  [Correlation Engine]
                        |
                [Alerts / Dashboards / SOAR]
                        |
               [Investigation / Case Management]
```

Componentes clave:

- **Collectors/Forwarders**: capturan logs desde fuentes y los env√≠an.
- **Parsing/Normalizaci√≥n**: transforma formatos distintos a un esquema com√∫n.
- **Enrichment**: agrega contexto (threat intel, owner, criticality).
- **Motor de correlaci√≥n**: aplica reglas, detecciones y anal√≠tica (SPL, KQL, Sigma, etc.).
- **Alerta / SOAR**: genera tickets, automatiza acciones (aislar host, bloquear IP).
- **Almacenamiento/search**: √≠ndices para b√∫squeda y an√°lisis hist√≥rico.

### Pipeline en detalle

1. **Ingesta**: syslog, agents (WinEvent, Sysmon), API cloud, EDR, Netflow, proxy.
2. **Parseo**: extraer campos (timestamp, source_ip, event_type, username, etc.).
3. **Normalizaci√≥n**: unificar nombres de campos para reglas (ej. `user.name`, `src.ip`).
4. **Enriquecimiento**: reputaci√≥n IP/URL, geoip, info de activos (owner, criticality), etiquetas MITRE.
5. **Correlaci√≥n y ML**: reglas de correlaci√≥n + detecciones basadas en ML/anomal√≠as.
6. **Priorizaci√≥n**: scoring por criticidad del activo + reputaci√≥n de IOCs + evidencia.
7. **Respuesta**: alerta SOC / SOAR workflows / playbooks.

### Fuentes de datos prioritarias (orden pr√°ctico)

1. EDR (endpoint) ‚Äî procesos, hashes, comportamiento.
2. Sysmon / Windows Event Logs ‚Äî procesos, network, file events.
3. AD / Auth logs ‚Äî logins, fallos, creaci√≥n de cuentas.
4. Firewall / Proxy / Web logs ‚Äî egress, conexiones a C2, descargas.
5. DNS logs ‚Äî detecci√≥n de tunneling / dominios nuevos.
6. Netflow / NDR ‚Äî vol√∫menes, patrones beaconing.
7. Cloud audit logs (AWS CloudTrail, Azure) ‚Äî configuraciones y accesos.
8. Email gateway / sandbox ‚Äî spearphishing detections.
9. DLP / File servers ‚Äî exfil y acceso a datos sensibles.

### Ejemplos concretos de detecci√≥n (reglas / consultas)

#### 1) Brute force (Windows) ‚Äî l√≥gica

Detectar 10 fallos de inicio de sesi√≥n en 5 minutos desde la misma IP a la misma cuenta ‚Üí alerta.

##### Splunk (SPL) ‚Äî ejemplo

```spl
index=wineventlog EventCode=4625
| stats count as failed by src_ip, TargetUserName, host
| where failed >= 10
| append [ search index=wineventlog EventCode=4624 | stats latest(_time) as last_success by TargetUserName, src_ip | where last_success > relative_time(now(), "-5m") ]
| where failed >= 10
| table src_ip, TargetUserName, failed
```

#### 2) PowerShell EncodedCommand + DNS a dominio raro (correlaci√≥n Capability + Infra)

- Si ves `powershell.exe -EncodedCommand` y en mismo host hay resoluci√≥n/conn a dominio sospechoso en 2 minutos ‚Üí alto riesgo.

##### Sigma (regla gen√©rica)

```yaml
title: PowerShell EncodedCommand Followed by Suspicious DNS
id: 1111-2222-3333
logsource:
  product: windows
detection:
  selection_powershell:
    EventID: 1
    ProcessName|endswith: '\powershell.exe'
    CommandLine|contains: "-EncodedCommand"
  selection_dns:
    EventID: 22
    QueryName|contains: "updates-svc."
  timeframe: 2m
  condition: selection_powershell and selection_dns
level: high
```

#### 3) Beaconing (C2) ‚Äî patr√≥n de conexiones peri√≥dicas

Buscar hosts con conexiones regulares (intervalos similares) a un endpoint externo peque√±o y con baja variabilidad.

##### Pseudoc√≥digo de correlaci√≥n

```
for each host:
  aggregate outbound_connections by destination, bin by 5m
  measure periodicity (standard deviation of inter-arrival)
  if periodicity < threshold and count > N:
    raise alert "Possible beaconing"
```

#### 4) Exfil por HTTPS (detectable)

- Regla: host que sube > X MB a un destino externo no en whitelist dentro de periodo T + proceso inusual.

### Caso pr√°ctico paso a paso (detecci√≥n realista)

1. EDR detecta ejecuci√≥n de `sysupdater.exe` (hash H) en `filesrv01`.
2. SIEM enriquece hash con VirusTotal ‚Üí malicious.
3. SIEM correlaciona: `filesrv01` resolvi√≥ `updates-svc.com` y conect√≥ a IP externa ‚Üí alerta alta.
4. SOC ejecuta playbook SOAR: aislar host, volcar memoria, crear ticket, bloquear dominio en proxy.
5. Hunt: buscar `H` y `updates-svc.com` en todos logs para alcance.

### Buenas pr√°cticas de implementaci√≥n (claves de √©xito)

- **Define casos de uso (use-cases)** antes de instalar: lista 10 detecciones cr√≠ticas (AD brute force, lateral movement, C2, exfil).
- **Empieza peque√±o y escalable**: piloto con endpoints cr√≠ticos ‚Üí escalar ingesti√≥n.
- **Normaliza y documenta campos**: evita "field hell".
- **Prioriza fuentes**: EDR y AD primero.
- **Tuning constante**: reduce falsos positivos (thresholds, suppression, aggregation).
- **Enriquecimiento autom√°tico**: CTI, asset DB, geolocation.
- **Integraci√≥n con SOAR**: automatizar contenci√≥n repetible (aislar host, bloquear IP).
- **Retenci√≥n y cumplimiento**: establece pol√≠ticas (ej. logs cr√≠ticos 1 a√±o, indices calientes/fr√≠os).
- **Monitorea costos**: ingesti√≥n/retenci√≥n impactos de licencia (GB/day).
- **Mapea a MITRE ATT\&CK**: para cobertura medible.

### Pitfalls comunes (errores a evitar)

- Ingestar _todo_ sin priorizar ‚Üí costos y ru√≠do.
- Reglas est√°ticas sin tuning ‚Üí avalancha de falsos positivos.
- Falta de metadata de activos ‚Üí mala priorizaci√≥n.
- No tener playbooks claros ‚Üí alertas sin acci√≥n.
- Ignorar pruebas (no validar con tests red team/Atomic Red Team).

### Integraci√≥n con SOAR y workflow de respuesta

- **Detecci√≥n ‚Üí Enriquecimiento ‚Üí Triage ‚Üí Acci√≥n autom√°tica**.
  Ejemplo de playbook autom√°tico:

1. Si `hash` es VT malicious (score > 70) y host cr√≠tico ‚Üí aislar host (EDR), bloquear IP en firewall, crear ticket en ITSM, notificar CISO.
2. Si `multiple failed logons` en AD ‚Üí trigger MFA reset and lock account, create incident for SOC analyst.

### M√©tricas y KPIs √∫tiles

- **MTTD** (Mean Time to Detect) ‚Äî meta: bajar lo m√°s posible.
- **MTTR** (Mean Time to Respond).
- **Alertas/d√≠a** y **FP rate** (falsos positivos %).
- **Cobertura**: % hosts con EDR, % DNS logs capturados.
- **Time to Triage** per alert.
- **Use-cases implementados vs planificados**.

### Selecci√≥n de soluci√≥n SIEM (qu√© mirar)

- **Modelo de licenciamiento** (GB ingest, EPS, nodes).
- **Capacidad de parsing y normalizaci√≥n** (conectores).
- **Soporte EDR / Cloud logs** (nativo).
- **SOAR integrado** o facilidad de integraci√≥n.
- **Escalabilidad / arquitecturas cloud**.
- **Capacidades de b√∫squeda hist√≥rica** y retenci√≥n costo-eficiente (hot/warm/cold).
- **Comunidad y reglas preconstruidas** (Sigma, detecciones MITRE).
  Ejemplos: Splunk, Elastic SIEM, Microsoft Sentinel, IBM QRadar, LogRhythm.

### Checklist r√°pido para poner un SIEM en producci√≥n

1. Definir objetivos y casos de uso (top 10).
2. Inventario de fuentes y priorizaci√≥n (EDR, AD, DNS, Proxy).
3. Deploy forwarders y test ingest.
4. Implementar parsing y normalizaci√≥n.
5. Enriquecer con CTI y Asset DB.
6. Implementar 5-10 reglas cr√≠ticas y playbooks SOAR.
7. Realizar tuning y baseline durante 30 d√≠as.
8. Ejecutar tests (Atomic Red Team / purple team).
9. Medir KPIs y ajustar.
10. Documentar runbooks y entrenar SOC.

### Mini-playbook de respuesta (cuando el SIEM genera una alerta cr√≠tica)

1. **Triage r√°pido**: validar telemetr√≠a, confirmar evidencia (hash, IP, user, host).
2. **Contain**: aislar host si es cr√≠tico.
3. **Recolect**: dumps de memoria, logs, EDR artifacts.
4. **Analiza**: identificar vector inicial y scope (buscar IOCs).
5. **Eradicate**: remover malware/persistencias, parchear vulnerabilidades.
6. **Recover**: restaurar desde backup, rotar credenciales.
7. **Lessons**: post-mortem y actualizar reglas/controles.

### Recursos pr√°cticos para seguir aprendiendo

- Repositorios de **Sigma rules** (reglas portables).
- **Atomic Red Team** (pruebas mapeadas a MITRE ATT\&CK).
- Documentaci√≥n de vendors SIEM (Splunk, Elastic, Sentinel).
- Ejercicios de purple teaming y labs de detecci√≥n.

---

[üîº](#√≠ndice)

---

## **353. Wazuh SIEM de c√≥digo abierto**

### 1) ¬øQu√© es Wazuh?

**Wazuh** es una plataforma de seguridad open-source que combina funcionalidades de **SIEM**, **EDR** (detecci√≥n en endpoints), **File Integrity Monitoring (FIM)**, **vulnerability detection**, **compliance auditing** y **orquestaci√≥n de respuesta**.
Se integra habitualmente con **Elasticsearch / OpenSearch + Kibana / OpenSearch Dashboards** para la indexaci√≥n y visualizaci√≥n, y expone una **API** y dashboards listos para SOC.

Ventajas clave:

- Open source y muy activo en la comunidad.
- Agente ligero para endpoints que recopila logs, eventos de procesos, integridad de archivos, etc.
- Correlaci√≥n y reglas personalizables.
- Integraci√≥n nativa con Elastic Stack u OpenSearch.
- Soporte para detecciones basadas en reglas y respuesta activa (scripts, bloqueo).

### 2) Arquitectura y componentes principales

Arquitectura t√≠pica (simple):

```
[Endpoints con Wazuh Agent] <---> [Wazuh Manager / Wazuh Indexer]
                                   |
              [Elasticsearch / OpenSearch] <- Index / Store
                                   |
                     [Kibana / OpenSearch Dashboards]
                                   |
                             [Wazuh API]
                                   |
                              [SOC Analysts]
```

Componentes:

- **Wazuh Agent**: software instalado en servidores y estaciones. Recopila: logs, procesos, conexiones de red, cambios en archivos, y ejecuta checks de configuraci√≥n. Env√≠a datos al manager por **TLS**.
- **Wazuh Manager**: recibe y procesa los eventos (decoding, rules, alerting), ejecuta FIM, an√°lisis de vulnerabilidades (cuando corresponde), y orquesta active response.
- **Wazuh Indexer / Elastic / OpenSearch**: almacena e indexa los eventos para b√∫squeda y visualizaci√≥n.
- **Wazuh API**: interfaz REST para extraer datos, gestionar agentes y automatizar tareas.
- **OpenSearch Dashboards / Kibana con Wazuh App**: visualizaci√≥n y paneles (Wazuh aporta su app para Kibana/Dashboards con vistas predefinidas).
- **Active Response**: scripts que pueden ejecutarse autom√°ticamente (bloquear IP en firewall, desactivar conta) desde manager o mediante SOAR.

### 3) Funcionalidades principales (qu√© hace Wazuh)

- **Recolecci√≥n de logs** (syslog, Windows Event Logs, text logs).
- **Decodificaci√≥n y normalizaci√≥n** (decoders).
- **Correlaci√≥n por reglas** (rules y rule sets, alerting).
- **File Integrity Monitoring (FIM)** ‚Äî detecta cambios en archivos/propiedades.
- **Detecci√≥n de intrusiones y EDR** ‚Äî procesos sospechosos, comandos inusuales, key detections (PowerShell, Mimikatz, etc.).
- **Vulnerability detection** ‚Äî escaneo y correlaci√≥n de CVEs con software instalado.
- **Compliance** ‚Äî checks para PCI-DSS, NIST, CIS Benchmarks.
- **Active response** ‚Äî ejecutar acciones (bloquear IP, desconectar host) ante alertas.
- **Threat intelligence enrichment** ‚Äî agregar reputaci√≥n de IP/URL.
- **Integraci√≥n con MITRE ATT\&CK** ‚Äî etiquetas y mapeo en dashboards.

#### 4) Flujo de trabajo (c√≥mo procesa un evento)

1. **Agente** detecta evento (p. ej. ProcessCreate o login fallido) y lo env√≠a al manager.
2. **Manager** aplica decoders para parsear campos y luego eval√∫a reglas (rule engine).
3. Si una regla coincide, se genera una **alerta** (con un level y a veces tags MITRE).
4. La alerta se env√≠a al indexer (Elastic/OpenSearch) y aparece en Dashboards.
5. Si configured, **active response** se ejecuta (script/block).
6. SOC triage ‚Üí investigaci√≥n (Wazuh App + Kibana/OS Dashboards) ‚Üí respuesta.

### 5) Ejemplo realista ‚Äî instalar agente y registrar (comandos orientativos)

> Nota: los comandos concretos var√≠an por distribuci√≥n y versi√≥n. Aqu√≠ tienes el **flujo t√≠pico** en Linux Debian/Ubuntu (ejemplo orientativo):

Instalar agente (ejemplo Debian):

```bash
# agregar repo y clave (ejemplo)
curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | sudo apt-key add -
echo "deb https://packages.wazuh.com/4.x/apt stable main" | sudo tee /etc/apt/sources.list.d/wazuh.list
sudo apt update
sudo apt install wazuh-agent
```

Configurar manager (en el agente):

```bash
sudo sed -i 's/manager_address.*/manager_address = manager.example.com/' /var/ossec/etc/ossec.conf
# registrar agente al manager
/var/ossec/bin/agent-auth -m manager.example.com
sudo systemctl enable --now wazuh-agent
```

En el **Wazuh Manager**: cuando el agente se autentica, el manager crea la entidad de agente y puedes ver estado con:

```bash
/var/ossec/bin/agent_control -l   # lista agentes
```

### 6) Decoders y reglas ‚Äî c√≥mo personalizar detecciones

Wazuh usa _decoders_ (para parsear logs) y _rules_ (para detectar condiciones).

- **Decoders**: transforman una l√≠nea de log en campos (user, srcip, process). Se colocan en `/var/ossec/etc/decoders/`.
- **Rules**: XML que matchea decoders y genera alertas; ubicadas en `/var/ossec/etc/rules/`.

#### Ejemplo: regla simple para SSH brute force (XML)

Crea archivo `/var/ossec/etc/rules/local_rules.xml` con:

```xml
<group name="local,">
  <rule id="100100" level="10">
    <decoded_as>sshd</decoded_as>
    <field name="rule">(Failed password|authentication failure)</field>
    <description>SSH failed login attempt detected</description>
    <group>authentication_failure,</group>
  </rule>

  <!-- Correlation rule: many failures from same IP -> brute force alert -->
  <rule id="100101" level="12" frequency="5" timeframe="60">
    <if_matched>100100</if_matched>
    <description>Possible SSH brute force attempt</description>
    <group>bruteforce,ssh,</group>
  </rule>
</group>
```

- `frequency="5"` y `timeframe="60"`: si la regla 100100 ocurre 5 veces en 60 segundos desde la misma fuente, eleva alerta 100101.

Despu√©s recargar reglas en manager:

```bash
sudo systemctl restart wazuh-manager
```

### 7) Ejemplo de alerta (JSON) ‚Äî c√≥mo la ver√°s en Elastic/OpenSearch

Cuando Wazuh indexa alertas, se pueden visualizar como documentos JSON. Un ejemplo simplificado de alerta:

```json
{
  "rule": {
    "id": "100101",
    "level": 12,
    "description": "Possible SSH brute force attempt",
    "group": ["bruteforce", "ssh"]
  },
  "agent": {
    "id": "001",
    "name": "filesrv01",
    "ip": "10.10.1.5"
  },
  "manager": {
    "name": "wazuh-manager"
  },
  "location": "/var/log/auth.log",
  "timestamp": "2025-09-12T10:23:18.000Z",
  "full_log": "Failed password for invalid user admin from 198.51.100.22 port 34692 ssh2"
}
```

En Kibana / OpenSearch Dashboards buscas por `rule.id: "100101"` o por `group: "bruteforce"` para ver todas las alertas.

### 8) File Integrity Monitoring (FIM) ‚Äî ejemplo de configuraci√≥n

Wazuh FIM monitoriza ficheros y directorios seg√∫n pol√≠ticas en `/var/ossec/etc/ossec.conf` (secci√≥n `<syscheck>`).

Ejemplo (fragmento ossec.conf):

```xml
<syscheck>
  <directories check_all="yes">/etc,/usr/bin,/opt/app</directories>
  <frequency>3600</frequency>
  <auto_ignore>no</auto_ignore>
  <scan_on_start>yes</scan_on_start>
</syscheck>
```

Cuando un archivo cambia (hash, permiso, owner), se genera una alerta tipo `syscheck` que aparece en el SIEM. √ötil para detectar cambios no autorizados en binarios o configuraci√≥n.

### 9) Vulnerability detection ‚Äî c√≥mo opera

Wazuh puede:

- Inventariar paquetes/software instalados en agentes (Windows/Linux).
- Correlacionar versiones con CVEs (usando fuentes de CVE feed).
- Generar alertas y dashboards de vulnerabilidades por host.

Esto permite priorizar parches por criticidad y exposici√≥n.

### 10) Active Response ‚Äî ejemplo: bloquear IP tras brute force

Wazuh tiene scripts de active response que se ejecutan en manager/agent. Ejemplo concept: si regla de brute force dispara, se ejecuta `firewalld-drop.sh` o `host-deny` para bloquear IP en el firewall.

Configurar active response en `ossec.conf`:

```xml
<active-response>
  <command>host-deny</command>
  <location>all</location>
  <rules_id>100101</rules_id>
  <timeout>600</timeout>
</active-response>
```

- `rules_id` = regla que dispara.
- `timeout` = tiempo que se mantendr√° la acci√≥n.

**Advertencia**: usar active response con cuidado (riesgo de bloquear IPs leg√≠timas). En producci√≥n, primero alertar y luego permitir auto-block con validaci√≥n.

### 11) Integraci√≥n con Elastic / OpenSearch y visualizaci√≥n

- Wazuh indexa los datos en Elasticsearch/OpenSearch.
- Instalar la **Wazuh App** (plugin) en Kibana/OpenSearch Dashboards te da dashboards preconstruidos: vistas de alertas, FIM, vulnerabilidades, integraci√≥n MITRE, estado de agentes, etc.
- Ejemplo de query KQL para buscar alertas de nivel >=10:

```
wazuh.alert.level >= 10
```

o buscar por evento:

```
wazuh.rule.groups: "bruteforce"
```

### 12) Escalado, HA y despliegue en producci√≥n

- **Peque√±as infra**: manager + indexer single node y varios agentes.
- **Producci√≥n**: separar roles: multiple managers (cluster), indexer cluster (Elasticsearch/OpenSearch cluster), load balancer, replicas, backups.
- **High Availability**: despliegues con Elasticsearch/OpenSearch en cluster y backups; Wazuh Manager puede configurarse con clusters/worker nodes (consultar versi√≥n espec√≠fica y gu√≠a Wazuh).
- **Escalado horizontal**: usar m√∫ltiples indexers y sharding para soportar alto EPS (events per second).

### 13) Buenas pr√°cticas y tuning

- **Priorizar fuentes**: primero EDR, AD, firewall, DNS, proxy.
- **Tunning de reglas**: empezar con reglas nativas, luego adaptar thresholds (frequency, timeframe) para reducir FP.
- **Normaliza campos**: haz que tu ingestion mapee campos claves (user.name, src.ip, host.name).
- **Retenci√≥n y coste**: archivar indices antiguos a cold storage y mantener √≠ndices calientes para queries frecuentes.
- **Hardening**: asegurar TLS entre agentes y manager, rotaci√≥n de claves, monitor health.
- **Testeo**: usa Atomic Red Team y simula ataques para validar reglas.
- **Versionado de reglas**: almacenar reglas personalizadas en control de versiones (git) y desplegar via CI/CD.

### 14) Casos de uso pr√°cticos

- **Detecci√≥n de intrusiones**: detectar ejecuci√≥n de Mimikatz, PowerShell encodado, lateral movement.
- **Compliance**: monitor de cambios en `/etc/ssh/sshd_config`, pol√≠ticas CIS.
- **Vulnerability management**: panel muestra hosts con CVEs cr√≠ticos.
- **Insider threat**: alertas de acceso a shares sensibles fuera de horario.
- **Threat hunting**: b√∫squeda retroactiva de IOC (hashes, dominios) en √≠ndices hist√≥ricos.

### 15) Limitaciones y consideraciones

- **Operaci√≥n y mantenimiento**: SIEM requiere tuning y recursos humanos para analizar alertas.
- **Escalabilidad**: para alto volumen debes planificar cluster Elasticsearch/OpenSearch y balanceo.
- **Active Response**: poderosa pero arriesgada; probar en labs y con reglas validadas.
- **Integraci√≥n y parsing**: algunos logs requieren decoders personalizados.

### 16) Ejemplo pr√°ctico completo (workflow de detecci√≥n de brute force)

1. **Logs entran**: `/var/log/auth.log` de varios servidores son recibidos por agentes y enviados al manager.
2. **Decoder**: Wazuh parsea la l√≠nea y la mapea a `sshd` decoder.
3. **Regla**: `100100` detecta fallo de login; `100101` (frequency rule) detecta 5 fallos en 60s ‚Üí alerta 100101.
4. **Active response** (opcional): bloquea IP durante 600s.
5. **SOC**: recibe alerta en Dashboard, mira detalles (`full_log`, `agent.ip`), realiza triage, decide bloquear a nivel de firewall global y abrir ticket en IT.
6. **Hunt**: buscar en logs hist√≥ricos la IP para ver si hay m√°s v√≠ctimas.

### 17) Recursos / pr√≥ximos pasos sugeridos

- Monta un lab con 1 manager + 1 indexer + 2 agents y practica: crear regla local, forzar evento y ver alerta en Dashboard.
- Usa **Atomic Red Team** para simular t√©cnicas y validar reglas Wazuh.
- Versiona tus reglas en git y automatiza deployment.
- Revisa la documentaci√≥n oficial Wazuh (gu√≠a de instalaci√≥n, administraci√≥n y reglas) y la Wazuh App para Kibana/OpenSearch.

---

[üîº](#√≠ndice)

---

## **354. Splunk El tutorial completo para principiantes**

### 1 ‚Äî ¬øQu√© es Splunk?

**Splunk** es una plataforma para indexar, buscar, visualizar y alertar sobre datos de m√°quina (logs, m√©tricas, eventos). Se usa en uso de casos como SIEM, monitoreo de infra, DevOps, an√°lisis de rendimiento y troubleshooting.

- Convierte datos sin estructura en ‚Äúeventos‚Äù indexables.
- Permite b√∫squedas interactivas con su lenguaje SPL (Search Processing Language).
- Ofrece dashboards, alertas, reportes y apps (Splunkbase).
- Versiones: **Splunk Free** (l√≠mite diario, un usuario), **Splunk Enterprise** (licencias por GB/d√≠a), y **Splunk Cloud**.

### 2 ‚Äî Arquitectura b√°sica y componentes

Resumen simplificado:

```
[Forwarders / Data Sources] ---> [Indexers (index & store)] <--- [Search Heads (user queries)]
                                    |
                          [Deployment Server / License Manager]
                                    |
                             [Kibana-like UI: Splunk Web]
```

Componentes clave:

- **Forwarder (Universal Forwarder)**: agente ligero que env√≠a datos a los indexers.
- **Indexers**: reciben, parsean e indexan eventos.
- **Search Head**: interfaz donde los analistas ejecutan b√∫squedas, crean dashboards y reports.
- **Deployment Server**: despliega apps/configs a forwarders (en entornos distribuidos).
- **License Manager**: controla volumen de ingesti√≥n.
- **Cluster Master / Indexer Cluster**: para alta disponibilidad y replicaci√≥n (entornos grandes).
- **KV Store, Lookup files, Apps**: capacidades extras.

### 3 ‚Äî Instalaci√≥n r√°pida (Linux, modo sencillo)

> **Nota:** descarga la versi√≥n desde splunk.com (no incluyo URLs concretos). Aqu√≠ el flujo b√°sico usando un tarball Linux (gen√©rico).

1. Subir tarball `splunk-<version>-linux-x86_64.tgz` a `/opt`:

```bash
cd /opt
sudo tar xvzf splunk-<version>-linux-x86_64.tgz
```

2. Iniciar Splunk por primera vez (aceptar licencia):

```bash
sudo /opt/splunk/bin/splunk start --accept-license
```

Se te pedir√° crear contrase√±a de `admin` (o te la fuerza a cambiar).

3. Habilitar arranque autom√°tico:

```bash
sudo /opt/splunk/bin/splunk enable boot-start
```

4. Comandos √∫tiles:

```bash
sudo /opt/splunk/bin/splunk status
sudo /opt/splunk/bin/splunk stop
sudo /opt/splunk/bin/splunk restart
```

Para sistemas Debian/RedHat hay paquetes `.deb` o `.rpm` con comandos `dpkg`/`rpm` ‚Äî el procedimiento es similar.

### 4 ‚Äî Ingesta de datos: formas y ejemplos

Formas comunes de meter datos en Splunk:

- **Monitor (archivos/dirs)**: Splunk observa archivos (ej. `/var/log/syslog`).
- **Forwarder (Universal Forwarder)**: recomendado para producci√≥n (ligero y eficiente).
- **Syslog (UDP/TCP)**: enviar logs desde dispositivos de red o rsyslog.
- **API / HTTP Event Collector (HEC)**: metrics o eventos desde aplicaciones.
- **Upload (manual)**: para pruebas/cargas puntuales.

#### Ejemplo: a√±adir un archivo local desde CLI (monitor)

```bash
/opt/splunk/bin/splunk add monitor /var/log/syslog -sourcetype syslog -index main
```

#### Ejemplo: configurar Universal Forwarder (UF)

En el host cliente:

```bash
# extrae UF
cd /opt
tar xvzf splunkforwarder-<ver>-linux-x86_64.tgz

# iniciar y aceptar licencia
sudo /opt/splunkforwarder/bin/splunk start --accept-license

# permitir arranque
sudo /opt/splunkforwarder/bin/splunk enable boot-start

# apuntar al indexer
sudo /opt/splunkforwarder/bin/splunk add forward-server indexer.example.com:9997 -auth admin:password

# monitorizar un log
sudo /opt/splunkforwarder/bin/splunk add monitor /var/log/messages -sourcetype syslog
```

En el **indexer** debes habilitar la escucha en 9997:

```bash
sudo /opt/splunk/bin/splunk enable listen 9997
```

### 5 ‚Äî Conceptos importantes al ingerir datos

- **index**: contenedor l√≥gico para datos (p.ej. `main`, `os`, `web`).
- **sourcetype**: etiqueta que describe formato del dato (p.ej. `syslog`, `apache:access`).
- **source**: origen f√≠sico (ruta de archivo, stdin, url).
- **host**: nombre/ID del host que env√≠a el evento.
- **timestamp**: Splunk detecta la hora; puedes forzar extracci√≥n con `props.conf` si es necesario.

**Buena pr√°ctica:** asigna `sourcetype` correctamente ‚Äî facilita parsing, extracci√≥n autom√°tica y uso del CIM (Common Information Model).

### 6 ‚Äî B√∫squedas b√°sicas con SPL (Search Processing Language)

SPL es el lenguaje de Splunk para buscar y transformar datos. Aqu√≠ ejemplos desde lo m√°s b√°sico.

#### 6.1 B√∫squeda simple

Buscar texto en √≠ndices:

```spl
index=main "failed password"
```

#### 6.2 Mostrar √∫ltimos 100 eventos

```spl
index=main sourcetype=syslog | head 100
```

#### 6.3 Contar eventos por usuario (ej. fallos SSH)

```spl
index=main sourcetype=linux_secure "Failed password"
| rex "Failed password for (?P<user>\w+)"
| stats count by user
| sort - count
```

Explicaci√≥n:

- `rex` extrae campo `user` con regex.
- `stats count by user` agrupa y cuenta.
- `sort - count` ordena descendente.

#### 6.4 Series temporal ‚Äî timechart

Eventos por hora:

```spl
index=main sourcetype=nginx_access
| timechart span=1h count
```

#### 6.5 Agregados y c√°lculos (eval)

Calcular kilobytes desde bytes:

```spl
index=main sourcetype=nginx_access
| eval kb = bytes/1024
| stats avg(kb) as avg_kb by clientip
| sort - avg_kb
```

#### 6.6 Buscar beaconing (simple heuristic)

Hosts que se conectan repetidamente al mismo destino:

```spl
index=network sourcetype=proxy
| stats count, mvcount(dest) as uniq_dest by src_ip, dest
| where count > 100 AND uniq_dest==1
```

(heur√≠stica: muchas conexiones desde un host al mismo destino).

### 7 ‚Äî Extracci√≥n de campos y `rex`

`rex` aplica una expresi√≥n regular sobre `_raw` (o campo indicado) para capturar grupos con `?P<name>`.

Ejemplo: extraer IP y user de l√≠nea SSH:

```spl
index=main sourcetype=linux_secure "Failed password"
| rex field=_raw "Failed password for (?:invalid user )?(?P<user>\w+) from (?P<src_ip>\d+\.\d+\.\d+\.\d+)"
| stats count by user, src_ip
| sort - count
```

Tambi√©n puedes usar **Field Extractor (UI)** para crear extracciones sin escribir regex.

### 8 ‚Äî Lookups (CSV) ‚Äî enriquecer eventos

Sube un CSV `users.csv` con columnas `user, department`. Luego:

```spl
index=main sourcetype=linux_secure "Failed password"
| rex "Failed password for (?P<user>\w+)"
| lookup users.csv user OUTPUT department
| stats count by department
```

Esto a√±ade el campo `department` desde el CSV.

### 9 ‚Äî Knowledge Objects: eventtypes, tags, macros, saved searches

- **Eventtypes**: agrupar eventos que cumplen un patr√≥n (p.ej. `failed_login`).
- **Tags**: etiquetar campos para b√∫squedas r√°pidas (`tag=authentication`).
- **Macros**: fragmentos reutilizables de SPL.
- **Saved searches / Alerts**: b√∫squedas guardadas; pueden programarse y notificar/ejecutar acciones.

Ejemplo: crear `saved search` que notifique si hay >50 fallos SSH en 10 minutos.

### 10 ‚Äî Dashboards y visualizaciones

1. Realiza una b√∫squeda que devuelva resultados (ej. conteo por usuario).
2. Haz **Save As ‚Üí Dashboard Panel** y elige visualizaci√≥n (chart, table).
3. Agrupa varios paneles en un dashboard para monitoreo.

Ejemplo: dashboard ‚ÄúAuth Overview‚Äù con:

- Panel 1: `index=main sourcetype=linux_secure | timechart span=1h count`
- Panel 2: `index=main sourcetype=linux_secure "Failed password" | rex ... | top user`
- Panel 3: `index=firewall | top src_ip`

### 11 ‚Äî Alerts (guardadas y acciones)

Guardar una b√∫squeda como alerta:

- Condici√≥n: `Number of Results` > 0 o `Custom condition` (p.ej. > 10).
- Trigger: realtime, scheduled (every 5m).
- Actions: send email, run script, webhook, create notable event (Splunk ES), trigger SOAR.

Ejemplo de alerta: ‚ÄúBrute Force SSH‚Äù:

- Search: `index=main sourcetype=linux_secure "Failed password" | stats count by src_ip | where count > 50`
- Trigger: schedule every 5m, if result>0 -> send email to SOC.

### 12 ‚Äî CIM (Common Information Model) y Splunk Enterprise Security (ES)

- **CIM** normaliza campos (authentication, network, endpoint) para que apps como **Splunk Enterprise Security (ES)** funcionen bien.
- Buenas pr√°cticas: mapear tus sourcetypes a CIM (via `props.conf` y `transforms.conf` o usando TA de Splunk).

### 13 ‚Äî Parsing avanzado y props/transforms (breve)

Si hay timestamps/patterns raros, usar `props.conf` y `transforms.conf` (indexer/forwarder) para:

- Forzar `TIME_FORMAT`, `TIME_PREFIX`.
- Extraer campos en index time / search time.
- Ruta de ejemplo en `props.conf`:

```
[your_sourcetype]
TIME_FORMAT = %Y-%m-%d %H:%M:%S
REPORT-extract = extract_fields
```

Y `transforms.conf` con regex para `extract_fields`.

> Nota: editar configs requiere reiniciar Splunk en muchos casos; usa `btool` para depurar.

### 14 ‚Äî Buenas pr√°cticas (ingesta, naming, rendimiento)

- **Nombres claros**: `index=prod_web`, `sourcetype=apache:access`.
- **Enriquecimiento en index-time vs search-time**: preferir search-time para flexibilidad (index-time aumenta uso de disco).
- **Control de volumen**: filtra qu√© ingieres (no todo).
- **Tama√±o de √≠ndices**: planifica retenci√≥n (hot/warm/cold/frozen).
- **Uso de UF para producci√≥n**: UF consume menos recursos que forwarders pesados.
- **Mant√©n la licencia bajo control**: monitoriza GB/day.
- **Seguridad**: TLS entre forwarders y indexers, roles/ACL para usuarios, habilitar auditor√≠a.

### 15 ‚Äî Escalado y despliegue distribuido

Modelos:

- **Single instance**: ideal para pruebas/labs.
- **Distributed (production)**: Forwarders ‚Üí Indexers (indexer cluster para HA) ‚Üí Search Heads (SH cluster para alta disponibilidad) ‚Üí Deployment Server.
- **Indexer clustering**: replicaci√≥n de datos entre nodos; **Search Head Clustering** permite queries distribuidas.

### 16 ‚Äî Troubleshooting r√°pido (comandos √∫tiles)

- Ver estado:

```bash
/opt/splunk/bin/splunk status
```

- Logs (manager/indexer):

```
/opt/splunk/var/log/splunk/splunkd.log
/opt/splunk/var/log/splunk/metrics.log
```

- Comprobar configuraci√≥n (btool):

```bash
/opt/splunk/bin/splunk btool props list --debug
/opt/splunk/bin/splunk btool inputs list --debug
```

- Restart:

```bash
/opt/splunk/bin/splunk restart
```

### 17 ‚Äî Ejemplo pr√°ctico completo: detectar fallos SSH ‚Üí alerta ‚Üí dashboard

**Paso 1 ‚Äî Indexar logs SSH (UF o monitor).**

**Paso 2 ‚Äî B√∫squeda para detecci√≥n (ad hoc):**

```spl
index=main sourcetype=linux_secure "Failed password"
| rex "Failed password for (?:invalid user )?(?P<user>\w+) from (?P<src_ip>\d+\.\d+\.\d+\.\d+)"
| stats count by src_ip, user
| sort - count
| head 20
```

**Paso 3 ‚Äî Guardar b√∫squeda como alerta**

- Schedule: every 5 minutes
- Condition: number of results > 0 (o where count > 50)
- Actions: email SOC + webhook to ticketing system

**Paso 4 ‚Äî Dashboard**

- Panel 1: timechart de fallos SSH por host:

```spl
index=main sourcetype=linux_secure "Failed password"
| timechart span=1h count by host
```

- Panel 2: top src_ip (la query previa).

### 18 ‚Äî Ecosistema: Apps y Splunkbase

- **Splunkbase**: marketplace de apps (TA = Technology Add-on, App = pack con dashboards).
- Apps √∫tiles: TA for _nginx_, _apache_, _windows_; Splunk App for _Windows Infrastructure_; \*Splunk Add-on for _Cisco_, _AWS_, _Azure_.
- **Enterprise Security (ES)**: soluci√≥n SIEM premium de Splunk (a√±ade correlation searches, notable events, risk-based alerting). Requiere licencias y mapping a CIM.

### 19 ‚Äî Seguridad y gobernanza

- Cambia contrase√±a `admin` inicial.
- Habilita HTTPS para Splunk Web.
- Usa roles/roles-based access control.
- Audita `audit.log` (qui√©n ejecut√≥ qu√© b√∫squeda).
- Restringe exportaci√≥n de datos a usuarios no autorizados.

### 20 ‚Äî Recursos de aprendizaje y siguiente paso pr√°ctico

- **Practica**: instala Splunk en una VM, instala UF en otra, a√±ade logs syslog, ejecuta las b√∫squedas anteriores.
- **Atomic Red Team**: emula t√©cnicas y valida tus reglas.
- **Splunk Docs**: gu√≠a oficial de instalaci√≥n y administraci√≥n.
- **Splunkbase**: descarga TAs para tecnolog√≠as que uses (NGINX, AWS, Cisco).
- **Cursos y certificaciones**: Splunk Fundamentals (p. ej. Splunk Fundamentals 1) para dominar SPL.

### 21 ‚Äî Resumen / Chuleta r√°pida

- Instalar Splunk ‚Üí habilitar UF en clientes ‚Üí asignar `sourcetypes` y `index` ‚Üí aprender SPL b√°sico (`search | stats | timechart | rex | eval`) ‚Üí crear alertas y dashboards ‚Üí ajustar reglas y mapear a CIM para seguridad.
- Empieza peque√±o, prioriza sources (EDR, AD, DNS, proxy) y tunea reglas para reducir falsos positivos.

---

[üîº](#√≠ndice)

---

## **355. Elastic Security Cree un SIEM dom√©stico potente**

> Resumen r√°pido: para un SIEM dom√©stico usar√°s **Elasticsearch + Kibana (Elastic Security app)**, **Elastic Agent / Beats** para recopilar logs, m√≥dulos (System, Suricata, Zeek), pipelines de ingesti√≥n para normalizar y la **Detection Engine** de Kibana para crear reglas/alertas. Con eso obtienes b√∫squeda, correlaci√≥n, hunting y respuesta ligera.

### 1. Arquitectura recomendada (home-lab)

Para una instalaci√≥n dom√©stica pr√°ctica y potente puedes empezar con un **single-node** o un **cluster peque√±o** si quieres HA. Topolog√≠a m√≠nima (sencilla y suficiente):

```
[Hosts Windows/Linux/Mobile] --(beats/agent)--> [Elastic Agent / Filebeat / Winlogbeat]
                                         \
                                          --> [Elasticsearch (indexer)]  <-- Kibana (Elastic Security)
                                         /
[Network Sensor: Suricata/Zeek] --(filebeat)-->
```

Componentes clave:

- **Elasticsearch** (indexa y archiva eventos)
- **Kibana** (UI ‚Äî Elastic Security app + dashboards)
- **Elastic Agent** (reemplaza muchos Beats; central en Fleet)
- **Filebeat / Winlogbeat / Auditbeat / Packetbeat** (si no usas Elastic Agent)
- **Network sensor (Suricata/Zeek)** + Filebeat para tr√°nsitos de red
- **Optional**: backup snapshots a NAS o S3, y un peque√±o SOAR (webhook ‚Üí script)

### 2. C√≥mo empezar r√°pido (opciones)

Dos caminos r√°pidos:

A) **Docker Compose** (r√°pido para laboratorio).
B) **Instalaci√≥n nativa** (Debian/Ubuntu) ‚Äî mejor rendimiento con control.

A continuaci√≥n doy un _docker-compose_ ejemplo y tambi√©n los pasos nativos m√≠nimos.

#### 2.1 Docker Compose (single-node de pruebas)

```yaml
# docker-compose.yml (ejemplo para laboratorio, no para producci√≥n)
version: "3.7"
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=changeme
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

volumes:
  esdata:
```

- Cambia versiones y credenciales.
- Luego `docker compose up -d`.
- En Kibana ([http://localhost:5601](http://localhost:5601)) activar Elastic Security ‚Üí instalar Fleet/Elastic Agent.

#### 2.2 Instalaci√≥n nativa (Ubuntu/Debian) ‚Äî m√≠nimos

1. Instala Elasticsearch y Kibana (paquetes `.deb` oficiales).
2. Ajusta `elasticsearch.yml` (single-node):

```yml
network.host: 0.0.0.0
discovery.type: single-node
xpack.security.enabled: true
```

3. Inicia Elasticsearch y Kibana, crea password para `elastic` con `elasticsearch-setup-passwords` o desde API.
4. En Kibana ‚Üí Integrations ‚Üí Fleet ‚Üí instalar Fleet Server (o usar agents standalone).

### 3. Agentes / recopilaci√≥n de datos (qu√© instalar en cada host)

Para un SIEM dom√©stico potente la cobertura m√≠nima es: _endpoints + auth logs + network + cloud_.

Recomendado por tipo:

- **Windows**: instala **Elastic Agent** (con integraci√≥n Endpoint) o **Winlogbeat** para eventos Windows.
- **Linux**: **Elastic Agent** o **Filebeat** + **Auditbeat** (procesos, login, syscall) + **Metricbeat** (m√©tricas).
- **Network**: **Suricata** o **Zeek** para IDS/flow; usar Filebeat para enviar logs a ES.
- **Router/Firewall**: enviar syslog a Filebeat o a un rsyslog local que Filebeat lea.
- **Cloud/Apps**: HEC (HTTP Event Collector) o Filebeat modules para AWS/GCP.

#### Ejemplo: instalar Elastic Agent (modo Fleet)

1. En Kibana ‚Üí Fleet ‚Üí Add agent ‚Üí genera command para instalar agent en host:

```bash
# ejemplo en Linux
sudo ./elastic-agent install \
  --url=https://<fleet-server>:8220 \
  --fleet-server-es=http://elasticsearch:9200 \
  --enrollment-token=<ENROLL_TOKEN>
```

2. Activa integraciones en Fleet (Endpoint security, System, Suricata, Zeek).

> Elastic Agent centraliza configuraci√≥n y facilita instalar Endpoint integration (detecci√≥n y respuesta).

### 4. Ingest pipelines / parsing ‚Äî ejemplos pr√°cticos

#### 4.1 Syslog (Linux) ‚Äî pipeline ingest con GROK

Ejemplo de ingest pipeline para l√≠neas de syslog:

```json
PUT _ingest/pipeline/syslog-pipeline
{
  "description": "parse syslog",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{SYSLOGTIMESTAMP:syslog.timestamp} %{HOSTNAME:host.name} %{DATA:syslog.program}(?:\\[%{POSINT:syslog.pid}\\])?: %{GREEDYDATA:syslog.msg}"]
      }
    },
    {
      "date": {
        "field": "syslog.timestamp",
        "formats": ["MMM  d HH:mm:ss","MMM dd HH:mm:ss"],
        "timezone": "UTC"
      }
    },
    {
      "set": {
        "field": "event.dataset",
        "value": "syslog"
      }
    }
  ]
}
```

- Configura Filebeat to use this pipeline: `output.elasticsearch.pipeline: syslog-pipeline` en `filebeat.yml`.

#### 4.2 Ingest suricata logs (Filebeat module)

```bash
# en el sensor Suricata
filebeat modules enable suricata
filebeat setup --dashboards
systemctl start filebeat
```

Filebeat crea √≠ndices con mappings ECS y pipelines predefinidos; perfecto para Elastic Security.

### 5. Normalizaci√≥n ECS ‚Äî por qu√© importa

Elastic usa **ECS (Elastic Common Schema)**. Normalizar a ECS facilita:

- Reglas reutilizables (Detection Engine)
- Correlaci√≥n entre datos (process.name, network.direction, dns.question.name)
- Reusabilidad de TI/ATT\&CK

Siempre que crees pipelines o decoders, mapear campos a ECS (`host.name`, `user.name`, `process.name`, `network.transport`, `destination.ip`, `dns.question.name`).

### 6. Detecci√≥n: reglas de Elastic Security (ejemplos)

En Kibana ‚Üí Security ‚Üí Detection ‚Üí Create rule. Tipos: _Query_, _EQL_, _Machine learning_, etc.

#### 6.1 Regla 1 ‚Äî PowerShell EncodedCommand (Query rule, KQL)

**KQL:** `process.name: "powershell.exe" and process.args: "*-EncodedCommand*"`
Y configuraci√≥n:

- Indexes: `logs-endpoint.events.process-*` (o `.security-*` seg√∫n tu ingest)
- Severity: high
- Actions: webhook to script / email.

#### 6.2 Regla 2 ‚Äî SSH brute force (threshold)

KQL b√°sico (syslog):

```
event.dataset: "linux.auth" and message: "Failed password"
```

Utiliza rule type _Threshold_ o _EQL_ para disparar si m√°s de N fallos desde misma source.ip / user en X minutos.

#### 6.3 Regla 3 ‚Äî DNS beaconing (EQL)

Detecci√≥n heur√≠stica simple: host que hace consultas a _pocos_ dominios pero con alta frecuencia.

EQL pseudocode:

```
sequence by host.name
  [dns where dns.question.name : "*example-bad*"]
  timespan = 5m
```

Mejor: agregaci√≥n sobre `dns.question.name` para ver hosts con >K queries a dominios raros en last 10m.

> Elastic permite programar estas y enviarlas a acciones (webhook, email, SIEM notebook).

### 7. Hunting: queries √∫tiles (KQL / ELasticsearch DSL)

#### 7.1 Buscar PowerShell encoded

KQL:

```
process.name: "powershell.exe" and process.args: "*EncodedCommand*" and host.os.type: "windows"
```

#### 7.2 Buscar ejecuci√≥n de Mimikatz (string en args)

KQL:

```
process.name: ("mimikatz.exe" or "lsass.exe") or process.args: "*sekurlsa*"
```

#### 7.3 Buscar beaconing (agregaci√≥n)

KQL approach (timechart-like):

```kql
event.dataset: "network_traffic"
| summarize count() by source.ip, destination.domain, bin(1m)
| where count > 100
```

(En Kibana Lens/Visualize usar `date histogram` y `terms` para detectar periodicidad.)

#### 7.4 Buscar exfil HTTPS grande

KQL:

```
network.direction: "outbound" and destination.port: 443 and network.bytes > 10485760
```

Filtro sobre `network.bytes` para detectar grandes subida en periodos cortos.

### 8. Dashboards y visualizaciones sugeridas

Paneles √∫tiles:

- **Overview**: ingest rate, alert rate, host count.
- **Authentication**: top failed logins, top source IPs, top users with failures.
- **Endpoint security**: process creation timeline, top suspicious processes, endpoint alerts.
- **Network**: top domains, top outbound IPs, top TLS certs, top Suricata signatures.
- **Threat hunting**: queries guardadas para PowerShell, suspicious scheduled tasks, LSASS access.

Kibana Canvas / Dashboard: arrastra visualizaciones basadas en KQL/EQL queries.

### 9. Automatizaci√≥n y respuesta (SOAR ligera)

Elastic permite **Actions** desde Kibana detections: webhook, index_record, email. Para respuesta autom√°tica dom√©stica:

- **Webhook ‚Üí script**: un peque√±o servicio en tu red que recibe la alerta y ejecuta el script (p. ej. bloquear IP en firewall UDM/OPNsense v√≠a API).
- **Elastic Agent Endpoint**: puede aislar procesos/hosts (si habilitas Endpoint integration y licencia la permite).
- **Alternativa OSS**: ElastAlert / Huginn / Shuffle para playbooks simples.

Ejemplo webhook payload (simplificado):

```json
{
  "alert_id": "abc123",
  "rule_name": "PowerShell EncodedCommand",
  "host": "workstation-1",
  "process.args": "-EncodedCommand IEX ...",
  "timestamp": "2025-09-12T12:00:00Z"
}
```

Tu script recibe y ejecuta: `iptables -I INPUT -s <source_ip> -j DROP` o `ufw deny from <ip>`.

### 10. Retenci√≥n, almacenamiento y sizing para un entorno dom√©stico

Planificaci√≥n sencilla:

- Estima logs/d√≠a: Windows host ‚âà 50‚Äì200 MB/d√≠a; Linux host 10‚Äì100 MB/d√≠a; Network sensors variable.
- Para un lab con 3‚Äì5 hosts + sensor, estima **1‚Äì3 GB/d√≠a**.
- Elasticsearch: reserva ES heap \~50% de RAM (m√°x 30‚Äì32 GB), disco r√°pido (SSD).
- Retenci√≥n: para casa, 7‚Äì30 d√≠as caliente y archivar a NAS o snapshot.
- Snapshots: usa snapshots peri√≥dicos a NAS/S3 para recuperaci√≥n.

Ejemplo: con 2 TB SSD puedes almacenar \~15‚Äì30 d√≠as a 2‚Äì4 GB/day con indices optimizados.

### 11. Seguridad de tu SIEM (hardening)

- Habilita **TLS** entre agentes y Elasticsearch/Kibana.
- Usa **autenticaci√≥n** (users/roles) en Kibana; no uses cuentas por defecto con contrase√±as d√©biles.
- Restringe acceso a Kibana por VPN o firewall (no abrir a Internet).
- Audita Kibana (audit logs) para cambios.
- Snapshots regulares y backups del .kibana index (config/dashboards).

### 12. Buenas pr√°cticas y recomendaciones finales

- **Empezar por casos de uso**: 10 detecciones cr√≠ticas (auth, endpoint, network, DNS, exfil).
- **ECS-first**: mapear campos a ECS para detecci√≥n reusable.
- **Tuning**: valida reglas con datos reales, ajusta thresholds.
- **Simula**: usa Atomic Red Team para probar detecciones.
- **Automatiza con cuidado**: acciones autom√°ticas (bloqueos) solo cuando confianza alta.
- **Documenta**: playbooks, runbooks, owners.
- **Monitoriza cluster**: m√©tricas ES (heap, disk, shards).

### 13. Ejemplo pr√°ctico completo (paso a paso, mini-lab)

1. Despliegue r√°pido: Docker Compose con Elasticsearch + Kibana (arranque).
2. En Kibana: habilita Fleet y crea enrollment token.
3. En un host Linux: ejecutar Elastic Agent install con enrol token.
4. Activar integraciones: System + Endpoint + Suricata.
5. Configurar Suricata en sensor y Filebeat en mismo host (module suricata).
6. Ver logs en Kibana ‚Üí Security ‚Üí detections ‚Üí activa reglas pre-construidas.
7. Crear regla: ‚ÄúPowerShell EncodedCommand‚Äù (KQL) y configurar webhook que llama script para bloquear IP.
8. Realizar prueba: ejecutar en Windows host `powershell -EncodedCommand` (solo en lab!) y verificar disparo y webhook.

### 14. Recursos y siguientes pasos pr√°cticos

- **Documentation**: Elastic docs (Instalaci√≥n Fleet, Elastic Agent, Detection Engine).
- **Atomic Red Team**: tests mapeados a ATT\&CK para validar.
- **Comunidad**: foros Elastic, GitHub (detections y dashboards compartidos).
- **Playbooks**: escribir runbooks para cada detecci√≥n cr√≠tica (triage steps).

### 15. Cheatsheet r√°pido (comandos / snippets √∫tiles)

**Filebeat enable system module**

```bash
filebeat modules enable system
filebeat setup --dashboards
systemctl restart filebeat
```

**Simple ingest pipeline put**

```bash
PUT _ingest/pipeline/syslog-pipeline
{ ... }   # (ver ejemplo en la secci√≥n pipelines)
```

**KQL example (PowerShell)**

```
process.name: "powershell.exe" and process.args: "*-EncodedCommand*"
```

**Elasticsearch search (DSL) ‚Äì find large uploads**

```json
GET /logs-*/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": { "network.direction": "outbound" } },
        { "range": { "network.bytes": { "gte": 10000000 } } }
      ]
    }
  }
}
```

---

[üîº](#√≠ndice)

---

| **Inicio**         | **atr√°s 9**            | **Siguiente 11**      |
| ------------------ | ---------------------- | --------------------- |
| [üè†](../README.md) | [‚è™](./11_9_ATT&CK.md) | [‚è©](./11_11_SOAR.md) |
