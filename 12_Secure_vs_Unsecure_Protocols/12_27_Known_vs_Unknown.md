| **Inicio**         | **atr√°s 26**              | **Siguiente 28**     |
| ------------------ | ------------------------- | -------------------- |
| [üè†](../README.md) | [‚è™](./12_26_Recovery.md) | [‚è©](./12_28_APT.md) |

---

## **√çndice**

| Temario                                                                                                                                              |
| ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| [406. De lo conocido a lo desconocido](#406-de-lo-conocido-a-lo-desconocido)                                                                         |
| [407. Atrapando todas las amenazas: conocidas, desconocidas y desconocidas](#407-atrapando-todas-las-amenazas-conocidas-desconocidas-y-desconocidas) |
| [408. Detectar amenazas conocidas](#408-detectar-amenazas-conocidas)                                                                                 |
| [409. C√≥mo afrontar las amenazas desconocidas](#409-c√≥mo-afrontar-las-amenazas-desconocidas)                                                         |

# **Conocido vs desconocido**

## **406. De lo conocido a lo desconocido**

![Recuperaci√≥n](/img/12_Secure_vs_Unsecure_Protocols/contencion_erradicacion_y_recuperacion.jpg "Recuperaci√≥n")

### üè¢ Teor√≠a empresarial

En las empresas, la ciberseguridad tradicional se ha basado en **lo conocido**: firmas de malware, reglas predefinidas en firewalls, listas negras de IP, y pol√≠ticas est√°ticas.

- Esto permite **detectar amenazas repetitivas**, pero es insuficiente ante **ataques nuevos, sin huella previa** (zero-day, APTs, ataques internos).

La transformaci√≥n hacia la **detecci√≥n proactiva con IA** cambia el enfoque:

- **De lo reactivo a lo predictivo.** La empresa no solo responde a alertas, sino que detecta comportamientos sospechosos antes de que se materialicen en un ataque.
- **De lo est√°tico a lo din√°mico.** Algoritmos de IA (machine learning, deep learning) aprenden el comportamiento normal de usuarios, dispositivos y redes, y detectan anomal√≠as.
- **De lo puntual a lo continuo.** La detecci√≥n es en tiempo real, alimentada por Big Data y flujos constantes de telemetr√≠a.

Ejemplo empresarial:

- Una entidad financiera que usa IA para detectar transacciones inusuales que no corresponden al historial del cliente, evitando fraudes antes de que el dinero salga.

### üìö La teor√≠a

En t√©rminos acad√©micos/t√©cnicos:

1. **Lo conocido**

   - Detecci√≥n basada en firmas y patrones ya catalogados.
   - Limitaci√≥n: solo funciona con amenazas registradas.

2. **Lo desconocido**

   - Amenazas sin precedentes (zero-day, ataques polim√≥rficos, insiders).
   - Necesita t√©cnicas como **an√°lisis de anomal√≠as, detecci√≥n no supervisada, correlaci√≥n de eventos**.

3. **Transformaci√≥n con IA**

   - **Modelos supervisados:** entrenados con ejemplos de ataques conocidos (clasificaci√≥n de malware, phishing, etc.).
   - **Modelos no supervisados:** detectan desviaciones en el comportamiento normal sin requerir muestras previas.
   - **IA generativa:** simulaci√≥n de ataques para fortalecer defensas y pruebas de penetraci√≥n automatizadas.
   - **Sistemas h√≠bridos:** combinaci√≥n de reglas tradicionales con IA que cubre lo desconocido.

Ejemplo t√©cnico:

- Un sistema de **User and Entity Behavior Analytics (UEBA)** con IA detecta que un empleado, que siempre accede en horario laboral desde Lima, ahora inicia sesi√≥n de madrugada desde otro pa√≠s. Aunque no hay firma de malware, el sistema alerta de un posible robo de credenciales.

### üìù El resumen

La ciberseguridad est√° evolucionando:

- Antes: se proteg√≠a principalmente de lo **conocido** (patrones de ataque registrados).
- Ahora: gracias a la **IA**, se puede detectar y responder tambi√©n a lo **desconocido**, analizando comportamientos y anomal√≠as.
- Resultado: una defensa **proactiva y din√°mica**, que no solo reacciona al ataque, sino que lo anticipa.

Ejemplo resumido:

‚û°Ô∏è Antes: antivirus detecta un virus por su firma.

‚û°Ô∏è Ahora: IA detecta un proceso sospechoso que cifra archivos aunque nunca haya visto ese ransomware.

---

[üîº](#√≠ndice)

---

## **407. Atrapando todas las amenazas: conocidas, desconocidas y desconocidas**

### 1. Amenazas **conocidas**

Son ataques que ya han sido identificados y catalogados.

- üîπ Ejemplo: un virus con firma registrada en una base de datos de antivirus.
- ‚úÖ C√≥mo se detectan: mediante **firmas, reglas IDS/IPS, listas negras y parches**.
- üìå Defensa cl√°sica: antivirus, firewalls, filtros de correo.

### 2. Amenazas **desconocidas**

Son variantes de ataques ya existentes, pero modificados para evadir defensas tradicionales.

- üîπ Ejemplo: un ransomware nuevo basado en otro ya conocido, que cambia su c√≥digo para no coincidir con firmas previas.
- ‚úÖ C√≥mo se detectan: mediante **an√°lisis de comportamiento, machine learning y sandboxing**.
- üìå Defensa moderna: **EDR/XDR** que observa qu√© hace el archivo (por ejemplo, si intenta cifrar archivos en masa).

### 3. Amenazas **desconocidas-desconocidas** (lo ‚Äúimpredecible‚Äù)

Son amenazas completamente nuevas, sin precedentes en la red de la v√≠ctima ni en registros globales. Tambi√©n llamadas **zero-day**.

- üîπ Ejemplo: una vulnerabilidad en un software que nunca antes fue explotada (ataque de d√≠a cero en un firewall).
- ‚úÖ C√≥mo se detectan: mediante **IA avanzada, detecci√≥n de anomal√≠as en tr√°fico y telemetr√≠a en tiempo real**.
- üìå Defensa: **Zero Trust, threat hunting proactivo, inteligencia de amenazas (TI)**.

### üîê C√≥mo atraparlas antes de que da√±en

1. **Capas de seguridad combinadas**

   - Firewall + IDS/IPS + EDR + XDR + SIEM.
   - Ejemplo: si un atacante rompe una capa, otra lo detiene antes del impacto.

2. **IA y machine learning**

   - Detecta comportamientos an√≥malos que los humanos no ver√≠an.
   - Ejemplo: un usuario descarga 10 GB a medianoche desde un servidor interno ‚Üí alerta autom√°tica.

3. **Modelo Zero Trust**

   - No confiar en nada por defecto, siempre verificar identidad y permisos.
   - Ejemplo: incluso dentro de la red, un empleado debe autenticarse para acceder a bases sensibles.

4. **Threat Hunting (caza proactiva de amenazas)**

   - Analistas buscan actividad sospechosa antes de que se convierta en un incidente.
   - Ejemplo: buscar conexiones ocultas a direcciones IP extra√±as en la red.

### üìå Ejemplo real unificado

Imagina un **hospital conectado a IoT** (c√°maras, monitores de pacientes, servidores con historiales m√©dicos):

- **Amenaza conocida** ‚Üí phishing con un malware ya catalogado. El antivirus lo bloquea.
- **Amenaza desconocida** ‚Üí una variante de ransomware cifra parte del sistema de facturaci√≥n, pero el EDR detecta el comportamiento an√≥malo y lo detiene.
- **Amenaza desconocida-desconocida** ‚Üí un atacante explota un fallo de d√≠a cero en un monitor IoT. El sistema de IA nota un tr√°fico extra√±o desde ese dispositivo hacia Rusia y lo a√≠sla antes de que robe datos.

Resultado: el hospital sigue funcionando sin interrupciones.

‚úÖ En resumen:

La clave para **‚Äúatrapar todas las amenazas antes de que puedan da√±arte‚Äù** es **complementar defensas tradicionales (para lo conocido) con detecci√≥n basada en IA, Zero Trust y threat hunting (para lo desconocido y lo impredecible)**.

---

[üîº](#√≠ndice)

---

## **408. Detectar amenazas conocidas**

Detectar _amenazas conocidas_ significa identificar ataques o artefactos que ya tienen huella: firmas, hashes, dominios/IPs maliciosas, patrones de comportamiento previamente documentados (IoC). Es la base de la defensa: si tienes las se√±ales de lo malo, puedes crear reglas y detenerlo r√°pidamente. Abajo te explico c√≥mo, con ejemplos pr√°cticos y buenas pr√°cticas.

### ¬øQu√© son las ‚Äúamenazas conocidas‚Äù (IoC t√≠picos)?

- **Hashes de archivos** (MD5/SHA1/SHA256) de malware.
- **Dominios o URLs** de C2 (command-and-control) o phishing.
- **Direcciones IP** asociadas a botnets o exfil.
- **Firmas de red** (patrones TCP/HTTP espec√≠ficos).
- **Registros/entradas de registro (Windows Registry)**, nombres de servicios, mutexes, rutas de archivo.
- **Comportamientos** detectables (p. ej. proceso que cifra muchos ficheros, descarga ejecutables desde URL conocida).

### Fuentes de intel para alimentar detecci√≥n

- Feeds comerciales (vendor TI), feeds OSS (AlienVault OTX, AbuseIPDB), bases CVE, MISP y feeds internos (IoC observados en tu entorno).
- Antivirus/EDR vendors (firmas y detecciones).
- Comunidades y repositorios (YARA rules, Snort/Suricata rules).
- VirusTotal / servicios de enriquecimiento para validar hashes/domains.

### Tecnolog√≠as y capas donde detectar

- **Antivirus / Endpoint (AV/EDR/XDR):** detectan hashes, comportamientos en endpoints y parent-child process trees.
- **IDS/IPS (Snort, Suricata):** inspecci√≥n de paquetes y firmas de red.
- **Network sensors (Zeek/Bro):** an√°lisis de protocolos y extracci√≥n de dominios/URLs.
- **SIEM (Splunk, Elastic):** centraliza logs y aplica correlaciones/consultas contra TI.
- **YARA:** detecci√≥n de patrones dentro de binarios/pefiles.
- **WAF / Proxy / DNS logs:** detecci√≥n de accesos a dominios/URLs maliciosas.

### Pipeline t√≠pico de detecci√≥n (c√≥mo funciona en la pr√°ctica)

1. **Ingesta** de telemetr√≠a (logs, netflow, EDR events, DNS, web proxy).
2. **Normalizaci√≥n** (mapear campos).
3. **Enriquecimiento** con threat intel (lookup contra listas de hashes/domains/IP).
4. **Correlaci√≥n / reglas / firmas** (al detectar coincidencia, generar alerta).
5. **Scoring / priorizaci√≥n** (criticialidad del activo, confianza del feed).
6. **Triage humano / playbook autom√°tico** (investigar, contener, remediar).

### Ejemplos pr√°cticos ‚Äî reglas y queries

#### 1) Regla Suricata para dominio C2

```text
alert http any any -> any any (msg:"ET MALWARE C2 Domain detected - malicious.example.com";
  flow:established,to_server;
  http.host; content:"malicious.example.com"; nocase;
  classtype:trojan-activity; sid:1000001; rev:1;)
```

> Si un cliente hace requests con `Host: malicious.example.com`, Suricata genera alerta.

#### 2) YARA ‚Äî detectar muestras con cadenas caracter√≠sticas

```yara
rule KnownBadSample {
  meta:
    author = "Gustavo"
    description = "Ejemplo: detecta strings usados por muestra maliciosa"
  strings:
    $s1 = "evil_function_init" ascii
    $s2 = "CONNECT /c2.php" ascii
  condition:
    any of them
}
```

> Escanea ejecutables o zips en repositorios para detectar coincidencias.

#### 3) Splunk (SPL) ‚Äî buscar hash de archivo en logs de endpoints

```spl
index=endpoint_logs sourcetype=edr:file_events file_sha256="SHA256_HASH_A_DETECTAR"
| stats count by host, user, file_path, _time
```

> Si el hash coincide, obtienes hosts afectados, usuarios y rutas.

#### 4) Splunk ‚Äî detectar PowerShell con `-EncodedCommand`

```spl
index=wineventlog EventCode=4688 Image="*\\powershell.exe" (CommandLine="*-EncodedCommand*" OR CommandLine="*IEX*")
| table _time host user CommandLine
```

> Patr√≥n conocido de t√©cnicas de ejecuci√≥n ofuscada; genera alerta para triage.

#### 5) Kibana / Elastic (KQL) ‚Äî acceso a dominio listado en feed TI

```
http.request.url : "*malicious.example.com*" or dns.question.name : "malicious.example.com"
```

> Encuentra client requests o consultas DNS.

### Ejemplo de flujo de detecci√≥n ‚Üí respuesta

1. TI feed ingesta: `malicious_hashes.csv` cargado al SIEM.
2. SIEM correlaciona `file_create` events en endpoints y encuentra coincidencia.
3. Alerta autom√°tica (alta prioridad) enviada al SOC.
4. SOAR enriquece alert con VirusTotal + asset owner + criticidad.
5. Playbook autom√°tico: aislar host en EDR + generar ticket + tomar snapshot forense.

### Buenas pr√°cticas para detectar amenazas conocidas

- **Actualizar firmas y feeds con frecuencia.** Parchea y renueva TI.
- **Gestionar la calidad de feeds:** prioriza feeds con baja tasa de falsos.
- **Enriquecer IoC con contexto:** activo cr√≠tico, vulnerabilidades, usuario.
- **Tuning de reglas:** evitar reglas demasiado gen√©ricas que generan _false positives_.
- **Versionar y probar firmas** en entornos de staging antes de desplegar en prod.
- **Aplicar whitelist para reducir ruido** (p. ej. hashes internos leg√≠timos).
- **Automatizar enriquecimiento** (VirusTotal, WHOIS, GeoIP, MISP) para acelerar triage.
- **Correlaci√≥n entre fuentes**: evento de red + evento de endpoint = mayor confianza.
- **Retirar/actualizar IoC obsoletos** (IPs din√°micas, dominios ya neutralizados).

### Limitaciones y c√≥mo compensarlas

- **Evasi√≥n:** atacantes usan ofuscaci√≥n/polimorfismo para evitar hashes y firmas. ‚Üí Compensar con EDR/behavioral detections y YARA.
- **Falsos positivos:** las reglas tienen ruido; ajustar basado en contexto.
- **Cobertura:** no todas las amenazas tienen IoC p√∫blicos. ‚Üí Complementar con detecci√≥n basada en anomal√≠as y threat hunting.

### M√©tricas clave (qu√© medir)

- **MTTD** (tiempo medio para detectar).
- **N√∫mero de detecciones de IoC** (por tipo: hash, domain, IP).
- **Tasa de falsos positivos** y tiempo de triage promedio.
- **Cobertura de endpoints / sensores** (porcentaje de hosts/reportando).

### Caso pr√°ctico resumido

- Un feed TI reporta `SHA256=ABC...` como ransomware. SIEM ingiere el feed (tarea programada).
- Un host reporta `file_create` con ese SHA256: SPL lo detecta ‚Üí alerta.
- SOAR a√≠sla host via EDR, captura snapshot y ejecuta playbook: revocar sessions, notificar CSIRT.
- Forense confirma infecci√≥n; se erradica y se restaura desde backup.

### Recomendaci√≥n final

Detectar amenazas conocidas es r√°pido y efectivo si tienes: **buenas fuentes de threat intel, sensores bien desplegados (EDR/IDS/SIEM), reglas firmes y procesos autom√°ticos de enriquecimiento y respuesta**. Pero no conf√≠es solo en firmas: comb√≠nalo con detecci√≥n de comportamiento y threat hunting para cubrir lo desconocido.

---

[üîº](#√≠ndice)

---

## **409. C√≥mo afrontar las amenazas desconocidas**

### 1) ¬øQu√© son las _amenazas desconocidas_ y por qu√© son un problema?

- **Definici√≥n:** ataques o artefactos que no existen en las bases de firmas ni en feeds de IOC: zero-day, malware polim√≥rfico, t√©cnicas nuevas de ejecuci√≥n o exfiltraci√≥n.
- **Por qu√© son peligrosas:** pasan bajo las defensas basadas en firmas; pueden permanecer m√°s tiempo sin ser detectadas; suelen usarse en campa√±as dirigidas (APT) o en compromisos de cadena de suministro.

### 2) Enfoque estrat√©gico (la idea principal)

Para cubrir lo desconocido necesitas pasar de ‚Äúdetectar lo que ya conozco‚Äù a **detectar comportamientos y anomal√≠as**. Resumen de enfoque:

1. **Telemetr√≠a amplia y de calidad** (endpoints, red, DNS, proxy, logs de aplicaciones, cloud).
2. **Detecci√≥n basada en comportamiento** (EDR/XDR, UEBA, reglas heur√≠sticas).
3. **Caza de amenazas proactiva (threat hunting)** con hip√≥tesis y modelos estad√≠sticos.
4. **Deception & canaries** para exponer lateral movement temprano.
5. **Respuesta r√°pida y prep. forense** (snapshots, volcado RAM, chain of custody).
6. **Retroalimentaci√≥n**: aprender y convertir hallazgos en detecciones autom√°ticas (detecci√≥n engineering).

### 3) T√©cnicas concretas para detectar lo desconocido

#### A. Telemetr√≠a m√≠nima imprescindible

Recolecta y centraliza:

- Eventos de procesos (EDR), command line, hashes.
- Conexiones de red y flow logs (VPC Flow, NetFlow).
- DNS queries y respuestas (resolver logs).
- Logs de proxy/HTTP, syslogs, autenticaciones (AD/AzureAD), cloud audit (CloudTrail).
- Integridad de archivos / cambios en masa.

> Sin datos no hay detecci√≥n. Conserva telemetr√≠a suficiente (retenci√≥n acorde al riesgo).

#### B. Detecci√≥n de comportamiento (EDR / XDR / UEBA)

- Detecciones por _t√©cnicas_, no por firma ‚Äî mapear a MITRE ATT\&CK.
- Ejemplos: ejecuci√≥n de procesos hijos inusuales (`winword -> powershell`), procesos que abren muchas conexiones salientes, procesos que renombraron sbin/cron o crean servicios.
- UEBA: detectar usuarios que se desv√≠an de su ‚Äúpeer group‚Äù (ubicaci√≥n, volumen de accesos, horarios).

#### C. Detecci√≥n por anomal√≠as y ML (no supervisado)

- Modelos de clustering / outlier detection (k-means, DBSCAN, isolation forest) para encontrar patrones raros.
- M√©tricas simples: z-score sobre bytes transferidos, n√∫mero de dominios visitados por hora, cantidad de procesos que escriben a disco.
- Importante: interpretar y explicar las detecciones (evitar ‚Äúcajas negras‚Äù sin contexto).

#### D. Rules & Indicators heur√≠sticos

- Reglas gen√©ricas que no dependen de firmas:

  - ‚ÄúProceso escribe >1000 ficheros en 10 min‚Äù.
  - ‚ÄúProceso con nombre leg√≠timo ejecuta base64/EncodedCommand‚Äù.
  - ‚ÄúHost consulta cientos de subdominios distintos (DNS flux)‚Äù.

#### E. Sandboxing y an√°lisis din√°mico

- Subir muestras sospechosas a sandbox (autom√°tico) y analizar comportamiento: sockets creados, archivos modificados, llamadas WinAPI.
- Usar ejecuci√≥n aislada para ver comportamientos que no son firmas.

#### F. Deception (honeypots/canaries)

- Crear cuentas canary, ficheros se√±uelo, m√°quinas trampas que idealmente no reciben tr√°fico leg√≠timo: si interact√∫an, indican compromiso temprano.

#### G. Threat Hunting program√°tico

- Definir hip√≥tesis (ej.: ‚Äú¬øHay se√±ales de exfil por DNS en los √∫ltimos 7 d√≠as?‚Äù) y ejecutar b√∫squedas peri√≥dicas.
- Convertir hallazgos en reglas o playbooks.

### 4) Medidas preventivas que reducen el impacto (no detectan, evitan)

- **Seguridad de identidad:** MFA obligatorio, bloqueo geogr√°fico, session management.
- **Minimizar superficie de ataque:** least privilege, aplicaci√≥n de control de aplicaciones (allowlist), deshabilitar RDP p√∫blico.
- **Patching & virtual patching:** respuesta r√°pida a vulnerabilidades p√∫blicas y WAF con reglas gen√©ricas.
- **Segmentaci√≥n y microsegmentaci√≥n:** limitar movimiento lateral.
- **Imagenes e infraestructura vetadas/provisionadas firmado:** AMIs/containers firmados (image provenance).
- **Backups frecuentes y probados** (air-gapped o immutable).

### 5) Playbook resumido para **un posible evento desconocido** (paso a paso)

**Detecci√≥n inicial (0‚Äìminutes)**

- Alerta: EDR/UEBA detecta anomal√≠a (ej. proceso que cifra muchos archivos).
- Triage r√°pido: confirmar con logs (process tree, command line, network connections).

**Contenci√≥n (first 0‚Äì60 min)**

- Aislar host con EDR (isolate).
- Tomar snapshot de disco y volcado de memoria si aplica.
- Capturar logs relevantes y copiar a bucket forense read-only.

**An√°lisis forense**

- Analizar volcado RAM para detectar payloads en memoria (Volatility/Velociraptor).
- Revisar parent/child process tree, m√≥dulos cargados, comunicaciones de red.

**Erradicaci√≥n**

- Si es malware: eliminar binario y persistencias o rebuild desde imagen limpia.
- Rotar credenciales asociadas con la cuenta/host.
- Cerrar vectores (aplicar reglas firewall, bloquear dominios).

**Recuperaci√≥n**

- Restaurar desde backup comprobado, reintroducir host con monitoreo intensivo.
- Aumentar detecci√≥n sobre indicadores derivados.

**Lecciones aprendidas**

- Crear nuevas reglas de detecci√≥n (EDR/SIEM), agregar IoC al TI, actualizar playbooks.

### 6) Ejemplos pr√°cticos y consultas √∫tiles

#### Ejemplo A ‚Äî Ransomware _nuevo_ detectado por comportamiento

- **Se√±al:** un proceso interno (no firmado) comienza a cifrar ficheros masivamente.
- **Regla heur√≠stica (SIEM):**

  ```spl
  index=file_events event=write | stats count by host, process_name, user, file_extension
  | where count > 500 AND file_extension IN ("docx","xls","pdf","db")
  ```

- **Acciones autom√°ticas:** aislar host, snapshot EBS, bloquear SMB share en firewall.

#### Ejemplo B ‚Äî Exfil v√≠a DNS (t√©cnica desconocida)

- **Se√±al:** muchos queries DNS a subdominios largos/aleatorios por una sola IP interna.
- **Query (Splunk):**

  ```spl
  index=dns sourcetype=dns_logs earliest=-1h
  | stats dc(query) as unique_subdomains, count by src_ip
  | where unique_subdomains > 200
  ```

- **Acci√≥n:** bloquear resoluci√≥n para ese host, capturar pcap del tr√°fico DNS, investigar proceso que gener√≥ queries.

#### Ejemplo C ‚Äî Comando PowerShell ofuscado (EncodedCommand)

- **Query (EDR/SIEM):**

  ```spl
  index=processes process_name="powershell.exe" CommandLine="*EncodedCommand*" OR CommandLine="*IEX*"
  | table _time host user CommandLine
  ```

- **Acci√≥n:** aislar host, extraer commandline y decodificar, sandbox de payload.

### 7) Detecci√≥n engineering y reducci√≥n de falsos positivos

- **Priorizaci√≥n por contexto**: activo cr√≠tico, usuario privilegiado, hora inusual.
- **Peer-group baselining**: compara el comportamiento con otros servidores del mismo rol.
- **Ajuste iterativo**: validar y medir tasa de falsos positivos; afinar umbrales.
- **Enriquecimiento autom√°tico**: GeoIP, reputaci√≥n de dominio, owner del asset.

### 8) Orquestaci√≥n y automatizaci√≥n segura

- Usa **SOAR** para tareas repetibles (snapshot, block IP, create ticket).
- **Human-in-the-loop** para acciones destructivas (terminate instance, revoke role).
- Registra todas las acciones (audit trail).

### 9) Cultura, procesos y people

- **Threat hunting regular** y ejercicios purple/red teaming.
- **Playbooks probados** en tabletop exercises.
- Formaci√≥n continua (phishing drills, awareness).
- SLA y escalamiento claros para incidentes de alta severidad.

### 10) M√©tricas clave para medir eficacia frente a lo desconocido

- **MTTD (Mean Time To Detect)** para anomal√≠as.
- **MTTR (Mean Time To Respond)** tras una anomal√≠a.
- % de detecciones no basadas en firmas.
- N√∫mero de hunts que derivan en detecciones nuevas.
- Falsos positivos por regla (para tuning).

### 11) Casos reales (resumidos, qu√© aprender)

- **Cadena de suministro (p. ej. SolarWinds):** soluci√≥n ‚Üí monitorizar cambios en software firmado, validar hashes y comportamiento de procesos de actualizaci√≥n.
- **Zero-day en un appliance IoT:** mitigaci√≥n ‚Üí segmentaci√≥n y aplicacion de microsegmentaci√≥n + bloqueo de comportamientos an√≥malos de dispositivo.
- **APT con living-off-the-land (LOTL):** detectar por uso an√≥malo de comandos leg√≠timos (PowerShell, WMI), crear reglas basadas en contextos y parent-child.

### 12) Checklist r√°pido (qu√© debes tener ya)

- [ ] Telemetr√≠a completa (EDR + DNS + proxy + network flows + cloud logs).
- [ ] Playbooks de contenci√≥n con snapshots forenses.
- [ ] Sistema UEBA y reglas de anomal√≠as configuradas.
- [ ] Programa de threat hunting activo (mensual/quincenal).
- [ ] Deception/canaries en segmentos sensibles.
- [ ] Automatizaci√≥n SOAR con guardrails humanos.
- [ ] Backups verificables y procesos de reinstalaci√≥n limpia.
- [ ] Inventario de activos y clasificaci√≥n por criticidad.

### Conclusi√≥n corta

Afrontar lo desconocido no es posible solo con firmas: requiere **datos buenos**, **detecci√≥n por comportamiento**, **caza proactiva**, **deception**, y **respuesta r√°pida**. Lo ideal es un ciclo continuo: **telemetr√≠a ‚Üí detecci√≥n ‚Üí hunting ‚Üí automatizaci√≥n ‚Üí aprendizaje**.

---

[üîº](#√≠ndice)

---

| **Inicio**         | **atr√°s 26**              | **Siguiente 28**     |
| ------------------ | ------------------------- | -------------------- |
| [üè†](../README.md) | [‚è™](./12_26_Recovery.md) | [‚è©](./12_28_APT.md) |
